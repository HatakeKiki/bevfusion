model:
  type: BEVAttn
  encoders:
    camera:
      vtransform:
        type: DepthAttnTransform
        in_channels: 256
        out_channels: 256
        feature_size: ${[image_size[0] // 8, image_size[1] // 8]}
        xbound: [-54, 54, 0.3]
        ybound: [-54, 54, 0.3]
        depth_attn_layers: 1
        depth_attn_cfg:
          type: DepthAttnLayer
          with_res: False
          embed_dim: 256
          num_heads: 8
          depth_attn: true
          sem_attn: false
          ffn_cfgs:
            type: FFN
            embed_dims: 256
            feedforward_channels: 512
            num_fcs: 2
            ffn_drop: 0.1
            act_cfg:
              type: ReLU
              inplace: true
          norm_cfg:
            type: LN
        positional_encoding:
          type: LearnedDepthPositionalEncoding
          input_channel: 1
          num_feats: 256
        # positional_encoding_key:
        #     type: SinePositionalEncoding
        #     num_feats: 128
        #     normalize: True
        downsample: 2
        with_bev_embedding: False
  decoder:
    backbone:
      in_channels: 256
  fuser:
    type: ConvFuser
    in_channels: [256, 256]
    out_channels: 256

freeze_lidar_components: True
freeze_camera_components: True

# optimizer:
#   type: AdamW
#   lr: 1.0e-4
#   weight_decay: 0.01
#   paramwise_cfg:
#     custom_keys: 
#       camera.neck:
#         lr_mult: 0.1
#         decay_mult: 1.0
#       vtransform:
#         lr_mult: 0.1
#         decay_mult: 1.0

max_epochs: 6
gt_paste_stop_epoch: -1

data:
  samples_per_gpu: 2
  workers_per_gpu: 4