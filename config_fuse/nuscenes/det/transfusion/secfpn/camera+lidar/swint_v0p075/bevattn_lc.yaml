model:
  type: BEVAttn
  encoders:
    camera:
      vtransform:
        type: DepthAttnTransform
        in_channels: 256
        out_channels: 256
        feature_size: ${[image_size[0] // 8, image_size[1] // 8]}
        xbound: [-54, 54, 0.3]
        ybound: [-54, 54, 0.3]
        depth_attn_layers: 1
        depth_attn_cfg:
          type: DepthAttnLayer
          embed_dim: 256
          num_heads: 1
          depth_attn: true
          sem_attn: false
          ffn_cfgs:
            type: FFN
            embed_dims: 256
            feedforward_channels: 512
            num_fcs: 2
            ffn_drop: 0.1
            act_cfg:
              type: ReLU
              inplace: true
          norm_cfg:
            type: LN
        positional_encoding:
          type: LearnedDepthPositionalEncoding
          input_channel: 1
          num_feats: 256
        # positional_encoding_key:
        #     type: SinePositionalEncoding
        #     num_feats: 128
        #     normalize: True
        downsample: 2
  decoder:
    backbone:
      in_channels: 256
  fuser:
    type: ConvFuser
    in_channels: [256, 256]
    out_channels: 256

freeze_lidar_components: True
freeze_camera_components: True

max_epochs: 6
gt_paste_stop_epoch: -1

data:
  samples_per_gpu: 2
  workers_per_gpu: 4


# image_size: [384, 1056]
# augment2d:
#   resize: [[0.57, 0.825], [0.72, 0.72]]
#   rotate: [-5.4, 5.4]
#   gridmask:
#     prob: 0.0
#     fixed_prob: true