# train_pkl: prediction_200.pkl
with_mask: true # 

model:
  encoders:
    camera:
      backbone: null
      neck: null

model:
  type: BEVAttnV2
  with_mask: true #
  mult_feat: true
  encoders:
    camera:
      backbone:
        type: ResNet
        depth: 101
        num_stages: 4
        out_indices: [1, 2, 3]
        frozen_stages: 1
        norm_cfg: 
          type: BN2d
          requires_grad: False
        norm_eval: True
        style: caffe
        dcn: 
          type: DCNv2
          deform_groups: 1
          fallback_on_stride: False # original DCNv2 will print log when perform load_state_dict
        stage_with_dcn: [False, False, True, True]
      neck:
        type: FPN
        in_channels: [512, 1024, 2048]
        out_channels: 256
        start_level: 0
        add_extra_convs: on_output
        num_outs: 4
        relu_before_extra_convs: True
      vtransform:
        type: DepthAttnTransform
        in_channels: 256
        out_channels: 256
        feature_size: ${[image_size[0] // 8, image_size[1] // 8]} # 
        xbound: [-54, 54, 0.6]
        ybound: [-54, 54, 0.6]
        depth_attn_layers: 1
        depth_attn_cfg:
          type: DepthAttnLayer
          with_res: False
          embed_dim: 256
          num_heads: 8
          ffn_cfgs:
            type: FFN
            embed_dims: 256
            feedforward_channels: 512
            num_fcs: 2
            ffn_drop: 0.1
            act_cfg:
              type: ReLU
              inplace: true
          norm_cfg:
            type: LN
        with_bev_embedding: True
        positional_encoding:
          type: LearnedDepthPositionalEncoding
          input_channel: 1
          num_feats: 256
        downsample: 1
        img_downsample_factor: [1, 2, 4, 8] # 
  # heads:
  #   object:
  #     in_channels: 512 #
  fuser:
    type: ConvFuser
    in_channels: [256, 256]
    out_channels: 256
  decoder:
    backbone:
      in_channels: 256


  # perspective_head:
  #   type: FCOSHead
  #   num_classes: 10
  #   in_channels: 256
  #   feat_channels: 256
  #   strides: [4, 8, 16, 32]
  #   # norm_on_bbox: False
  #   # dcn_on_last_conv: False
  #   center_sampling: False
  #   center_sample_radius: 1.5
  #   loss_centerness:
  #     type: CrossEntropyLoss
  #     use_sigmoid: True
  #     loss_weight: 0.5
  #   loss_cls:
  #       type: FocalLoss
  #       use_sigmoid: True
  #       gamma: 2.0
  #       alpha: 0.25
  #       loss_weight: 0.75
  #   loss_bbox: 
  #     type: IoULoss
  #     loss_weight: 0.0


freeze_lidar_components: True
freeze_decoder: False

lr_config:
  policy: CosineAnnealing
  warmup: linear
  warmup_iters: 2000
  warmup_ratio: 0.3333333
  min_lr_ratio: 1.0e-3

optimizer:
  type: AdamW
  lr: 5.0e-5

max_epochs: 6
gt_paste_stop_epoch: -1

data:
  samples_per_gpu: 2
  workers_per_gpu: 4

# evaluation:
#   interval: 3