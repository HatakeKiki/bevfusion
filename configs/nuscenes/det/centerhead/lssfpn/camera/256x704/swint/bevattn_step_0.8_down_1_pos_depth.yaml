model:
  type: BEVAttn
  encoders:
    camera:
      vtransform:
        type: DepthAttnTransform
        in_channels: 256
        out_channels: 256
        feature_size: ${[image_size[0] // 8, image_size[1] // 8]}
        xbound: [-51.2, 51.2, 0.8]
        ybound: [-51.2, 51.2, 0.8]
        zbound: [-10.0, 10.0, 20.0]
        dbound: [1.0, 60.0, 0.7]
        depth_attn_layers: 1
        depth_attn_cfg:
          type: DepthAttnLayer
          embed_dim: 256
          num_heads: 1
          depth_attn: true
          sem_attn: false
          ffn_cfgs:
            type: FFN
            embed_dims: 256
            feedforward_channels: 512
            num_fcs: 2
            ffn_drop: 0.1
            act_cfg:
              type: ReLU
              inplace: true
          norm_cfg:
            type: LN
        positional_encoding:
          type: LearnedDepthPositionalEncoding
          input_channel: 1
          num_feats: 256
        # positional_encoding_key:
        #     type: SinePositionalEncoding
        #     num_feats: 128
        #     normalize: True
        downsample: 1
  decoder:
    backbone:
      in_channels: 256


# optimizer:
#   type: AdamW
#   lr: 0.0002
#   weight_decay: 0.01
#   paramwise_cfg:
#     custom_keys:
#       absolute_pos_embed:
#         decay_mult: 0
#       relative_position_bias_table:
#         decay_mult: 0
#       encoders.camera.backbone:
#         lr_mult: 0.1

# optimizer_config:
#   grad_clip:
#     max_norm: 35
#     norm_type: 2

# lr_config:
#   policy: CosineAnnealing
#   warmup: linear
#   warmup_iters: 500
#   warmup_ratio: 0.3333333
#   min_lr_ratio: 0.001

# max_epochs: 24
# data:
#   samples_per_gpu: 1


