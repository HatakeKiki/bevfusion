model:
  type: BEVAttnV2
  mult_feat: true
  encoders:
    camera:
      backbone:
        out_indices: [0, 1, 2, 3]
      neck:
        type: FPN
        in_channels: [96, 192, 384, 768]
        num_outs: 4
        norm_cfg: null
        act_cfg: null
      vtransform:
        type: DepthAttnTransform
        in_channels: 256
        out_channels: 256
        feature_size: ${[image_size[0] // 4, image_size[1] // 4]}
        xbound: [-51.2, 51.2, 0.4]
        ybound: [-51.2, 51.2, 0.4]
        zbound: [-10.0, 10.0, 20.0]
        dbound: [1.0, 60.0, 0.5]
        depth_attn_layers: 1
        depth_attn_cfg:
          type: DepthAttnLayer
          embed_dim: 256
          num_heads: 8
          ffn_cfgs:
            type: FFN
            embed_dims: 256
            feedforward_channels: 512
            num_fcs: 2
            ffn_drop: 0.1
            act_cfg:
              type: ReLU
              inplace: true
          norm_cfg:
            type: LN
        downsample: 2
        img_downsample_factor: [1, 2, 4, 8]
        # positional_encoding:
        #   input_channel: 1
        #   num_feats: 256
        #   type: LearnedDepthPositionalEncoding
  decoder:
    null
    # backbone:
    #   in_channels: 256
    # neck:
    #   in_channels: [128, 512]
    #   scale_factor: 2
    # backbone:
    #   type: GeneralizedResNet
    #   in_channels: 256
    #   blocks:
    #     - [2, 128, 2]
    # neck:
    #   in_channels: [128]
    #   scale_factor: 2

data:
  samples_per_gpu: 4
  workers_per_gpu: 4

# optimizer:
#   type: AdamW
#   lr: 5.0e-5

